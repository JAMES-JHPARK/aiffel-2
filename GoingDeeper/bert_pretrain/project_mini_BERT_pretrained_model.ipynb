{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e56354",
   "metadata": {},
   "source": [
    "# 프로젝트 : mini BERT 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dabd7e7",
   "metadata": {},
   "source": [
    "지금까지 BERT 모델을 pretrain하는 험난한 여정을 잘 따라오셨나요?\n",
    "\n",
    "이번 프로젝트의 과제는 간단합니다.\n",
    "\n",
    "vocab size를 8000으로 줄이고, 전체 파라미터 사이즈가 1M 정도가 되는 아주 작은 mini BERT 모델을 만들어 10 Epoch까지 학습시킨 모델을 만들어 보는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0556a03",
   "metadata": {},
   "source": [
    "## 라이브러리 버전을 확인해 봅니다.\n",
    "---\n",
    "사용할 라이브러리 버전을 둘러봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb1079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "1.3.3\n",
      "3.4.3\n",
      "2.0.9\n",
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib\n",
    "import json\n",
    "import re\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(numpy.__version__)\n",
    "print(pandas.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(json.__version__)\n",
    "print(re.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba998cbb",
   "metadata": {},
   "source": [
    "## 1. Tokenizer 준비\n",
    "---\n",
    "SentencePiece 모델을 이용해 BERT의 MLM 학습용 데이터를 만드세요.\n",
    "\n",
    "이를 위해 한글 나무 위키 코퍼스로부터 8000의 vocab_size를 갖는 sentencepiece 모델을 만들어 보세요. BERT에 사용되는 주요 특수문자가 vocab에 포함되어야 합니다. (시간이 부족하다면 클라우드에 저장된 sentencepiece 모델을 사용하세요.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d944f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# tf version 및 gpu 확인\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57afab01",
   "metadata": {},
   "source": [
    "### model 만들기\n",
    "```bash\n",
    "    $ python\n",
    "    >>> import sentencepiece as spm\n",
    "    >>> import os\n",
    "    >>> corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "    >>> prefix = os.getenv('HOME')+'/aiffel/bert_pretrain/models/ko_8000'\n",
    "    >>> vocab_size = 8000\n",
    "    >>> spm.SentencePieceTrainer.train(f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={vocab_size + 7} --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS] --user_defined_symbols=[SEP],[CLS],[MASK]\")\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5517ed",
   "metadata": {},
   "source": [
    "SentencePieceTrainer 에 전달하는 파라미터 설명은 setencepiece/doc/options.md 를 확인하세요.\n",
    "\n",
    "클라우드에 저장된 파일을 사용하기 위해서 아래 명령어로 심볼릭 링크를 걸어 준 후 계속 진행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba4110b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/data'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/models'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_8000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa06ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q. 특수 token 7개를 제외한 나머지 token들을 출력해봅시다.\n",
    "vocab_list = []\n",
    "for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):\n",
    "            #print(vocab.decode([id]), end=' ')\n",
    "            vocab_list.append(vocab.decode([id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eaa59a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d4645",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 (1) MASK 생성\n",
    "---\n",
    "BERT의 MLM에 필요한 빈칸(mask)을 학습 데이터 전체 토큰의 15% 정도로 만들어 주세요. 그 중 80%는 [MASK] 토큰, 10%는 랜덤한 토큰, 나머지 10%는 원래의 토큰을 그대로 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8b1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
    "    :param vocab_list: vocab list (random token 용)\n",
    "    :return tokens: mask된 tokens\n",
    "    :return mask_idx: mask된 token의 index\n",
    "    :return mask_label: mask된 token의 원래 값\n",
    "    \"\"\"\n",
    "    # 단어 단위로 mask 하기 위해서 index 분할 (띄어쓰기)\n",
    "    cand_idx = []  # word 단위의 index array\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):  # u\"\\u2581\"는 단어의 시작을 의미하는 값\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "\n",
    "    # random mask를 위해서 순서를 섞음 (shuffle)\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    # mask_lms 정렬 후 mask_idx, mask_label 추출 (sorted 사용)\n",
    "    mask_lms = []  # mask 된 값\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "              break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "              continue\n",
    "        dice = random.random()  # 0과 1 사이의 확률 값\n",
    "\n",
    "        for index in index_set:\n",
    "            masked_token = None\n",
    "            if dice < 0.8:  # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: # 10% keep original\n",
    "                masked_token = tokens[index]\n",
    "            else:  # 10% random word\n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "    \n",
    "    # 순서 정렬 및 mask_idx, mask_label 생성\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10cfc2a",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리 (2) NSP pair 생성\n",
    "---\n",
    "BERT의 pretrain task인 NSP는 두 문장이 연속하는지 확인하는 것입니다. 이를 위해 2개의 문장을 짝지어 50%의 확률로 TRUE와 FALSE를 지정해 주세요.\n",
    "\n",
    "두 문장 사이에 segment 처리를 해주세요. 첫 번째 문장의 segment는 0, 두 번째 문장은 1로 채워준 후 둘 사이에 구분자인 [SEP] 등을 넣어주세요.\n",
    "\n",
    "MLM과 NSP는 동시에 학습된다는 것을 염두에 두고 학습 데이터를 구성해 보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d327d0d3",
   "metadata": {},
   "source": [
    "짝지은 두 문장을 그대로 두면 NSP task의 true label 케이스가 되고, 둘의 순서를 뒤바꾸면 false label 케이스가 되겠죠?\n",
    "\n",
    "두 문장의 최대 길이를 유지하도록 trim을 적용한 후 50%의 확률로 true/false 케이스를 생성해 보겠습니다.\n",
    "\n",
    "token A의 길이가 max_seq보다 길면 앞에서부터 토큰을 제거하고, token B의 길이가 길면 뒤에서부터 토큰을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f096f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a9f22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    # for [CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])  # line 단위로 추가\n",
    "        current_length += len(doc[i])  # current_chunk의 token 수\n",
    "        \n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq): # 마지막 줄 이거나 길이가 max_seq 이상 인 경우, 학습 데이터를 만듭니다. \n",
    "            #print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "            # token a\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            # token b\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "\n",
    "            if random.random() < 0.5:  # 50% 확률로 swap\n",
    "                is_next = 0    # False\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1   # True\n",
    "            # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "\n",
    "            # tokens & segment 생성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520579e8",
   "metadata": {},
   "source": [
    "## 4. 데이터 전처리 (3) 데이터셋 완성\n",
    "---\n",
    "BERT pretrain 데이터셋을 생성해, json 포맷으로 저장하세요. 데이터셋의 사이즈가 크므로np.memmap을 사용해 메모리 사용량을 최소화해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12f0e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3957761"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "\n",
    "# line count 확인\n",
    "total = 0\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    for line in in_f:\n",
    "        total += 1\n",
    "\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd8d51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "            \n",
    "    # 특수문자 7개를 제외한 vocab_list 생성\n",
    "    vocab_list = [vocab.id_to_piece(id) for id in range(7, len(vocab)) if not vocab.is_unknown(id)]\n",
    "\n",
    "\n",
    "    with open(in_file, \"r\") as in_f, open(out_file, \"w\") as out_f:\n",
    "        doc = []\n",
    "        for line in tqdm(in_f, total=sum(1 for _ in open(in_file, \"r\")), desc=\"Processing lines\"):\n",
    "            line = line.strip()\n",
    "            if line == \"\":  # line이 빈줄일 경우 (새로운 단락)\n",
    "                if doc:\n",
    "                    save_pretrain_instances(out_f, doc)\n",
    "                    doc = []\n",
    "            else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
    "                pieces = vocab.encode_as_pieces(line)\n",
    "                if pieces:\n",
    "                    doc.append(pieces)\n",
    "        if doc:  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "            save_pretrain_instances(out_f, doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86979c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a3eb08b56747f89242580703005157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing lines:   0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrain_json_path = os.getenv('HOME')+'/aiffel/bert_pretrain/data/bert_pre_train_8000.json'\n",
    "\n",
    "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4a292ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "918189"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라인수\n",
    "total = 0\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f20c7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seq = 128\n",
    "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
    "max_seq = n_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3da68f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "enc_tokens = np.memmap(filename='enc_tokens_8000.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "segments = np.memmap(filename='segments_8000.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "labels_nsp = np.memmap(filename='labels_nsp_8000.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "labels_mlm = np.memmap(filename='labels_mlm_8000.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "\n",
    "#enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad03c3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8a6b6fb1ad4aa1b10a014496dbc628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/918189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_234/858356973.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_234/858356973.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_234/858356973.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "# 라인 단위로 처리\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for i, line in enumerate(tqdm(f, total=total)):\n",
    "        if 5 < i:  # 테스트를 위해서 5개만 확인\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        # encoder token\n",
    "        enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "        enc_token += [0] * (n_seq - len(enc_token))\n",
    "        # segment\n",
    "        segment = data[\"segment\"]\n",
    "        segment += [0] * (n_seq - len(segment))\n",
    "        # nsp label\n",
    "        label_nsp = data[\"is_next\"]\n",
    "        # mlm label\n",
    "        mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "        mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "        label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "        label_mlm[mask_idx] = mask_label\n",
    "\n",
    "\n",
    "        assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "        enc_tokens[i] = enc_token\n",
    "        segments[i] = segment\n",
    "        labels_nsp[i] = label_nsp\n",
    "        labels_mlm[i] = label_mlm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b855cd",
   "metadata": {},
   "source": [
    "## 🔶 load_pre_train_data() : 학습에 필요한 데이터를 로딩하는 함수\n",
    "---\n",
    "np.memmap을 사용해 메모리 효율적으로 만들어진 데이터를 로딩하는 함수를 아래와 같이 구성하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30ecea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "    enc_tokens = np.memmap(filename='enc_tokens_8000.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments_8000.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp_8000.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm_8000.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45518c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d819598bce5461abe209ba26c931f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_234/97267933.py:42: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_234/97267933.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_234/97267933.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load early stop 128000 128000\n"
     ]
    }
   ],
   "source": [
    "# 128000건만 메모리에 로딩\n",
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=128000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db6499de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([   5,   10, 1605, 3599, 1755, 3630,   41, 3644,  830, 3624, 1135,\n",
       "           52, 3599,   13,   81,   87, 1501, 2247,   25, 3779, 3873, 3667,\n",
       "         3631, 3813, 3873, 4196, 3636, 3779, 3601,  249, 3725, 1232,   33,\n",
       "           52, 3599,    6,    6,    6, 6322, 2780,   14, 1509,  168, 3877,\n",
       "          414,  165, 1697, 4290, 3873, 3703, 3683,  593,   21, 5007,  399,\n",
       "         1927, 3607,    6,    6,    6,    6,    6,    6,  103, 4313, 4290,\n",
       "          613, 3638, 3718,   98, 3878, 3656,  256, 2543,  309,  337, 3735,\n",
       "          181, 3616, 3603,  489,  376, 3599,    4,    6,    6,  207, 3714,\n",
       "            6, 1042,  103, 3610, 3686, 3718,    6,    6,   37, 3418,  416,\n",
       "          810, 3666, 3625,  131, 3662,    7, 3629,  203,  241, 3602, 1114,\n",
       "         3724,  788,  243,    6,    6,    6,  663, 1647, 3682, 3682, 3625,\n",
       "          203, 3008, 3625, 3616,   16, 3599,    4], dtype=int32),\n",
       " memmap([   5, 3676,  848, 3784, 1931,   58, 3676,  416, 2316, 3619, 3625,\n",
       "         3617, 3744, 4335,   12, 3625, 3616,  175, 3662,    7, 3629,  203,\n",
       "            6,    6,    6,    6,    6,    6,  143, 3625, 3616,  131, 3662,\n",
       "          342, 3629, 3616, 3602,  176,  334,  829, 1115, 3665,    6,    6,\n",
       "         3451, 1633,  375,  671, 1644, 3608,  547, 3423,  765,  815, 3604,\n",
       "            6,    6,    6, 2375, 3608, 3604,  532, 2589, 3599,    4,  307,\n",
       "          323,    6,  321, 3611,  622,  122, 3725, 3620, 3627, 3837, 3608,\n",
       "            6,  176,  268, 4082,   94,  567, 4014, 3617, 7474, 3616, 3830,\n",
       "           66, 3590,  307,  192, 1272,  158, 3788,  353, 3599,  202,  316,\n",
       "         3600,  176,   10,  323,  476, 3663, 1329,  605,  238, 3631, 2470,\n",
       "         3604, 1939,  106, 3627,   13,    6,    6, 1128,   48,    6,    6,\n",
       "          848, 3784, 3833,    8, 3637, 2263,    4], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 0,\n",
       " 1,\n",
       " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,  479, 3652, 3625,  243,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,  813,   17, 3599,  307,  587,  931,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,   18, 3686,    0,    0,\n",
       "         3324,    0,    0,    0,    0,    0,  207, 3714,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,   49, 3632,  796,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
       " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          578, 3652, 3625, 3617, 4148, 3665,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0, 1381, 4148,\n",
       "         3451,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          752, 3608, 3604,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0, 2143,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          347,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,  162,  490,    0,    0,   28, 3599,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처음과 마지막 확인\n",
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe97d0",
   "metadata": {},
   "source": [
    "## 5. BERT 모델 구현\n",
    "---\n",
    "pad mask, ahead mask 함수, gelu activation 함수, parameter initializer 생성 함수, json을 config 형태로 사용하기 위한 유틸리티 함수를 먼저 만들어 두세요.\n",
    "\n",
    "Embedding 레이어, Transformer encoder 레이어, BERT 레이어를 구성한 후, pretraine용 BERT 모델을 만들어 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35752418",
   "metadata": {},
   "source": [
    "## BERT 모델 구현\n",
    "이제 본격적으로 BERT model을 구현해 보겠습니다.\n",
    "\n",
    "BERT가 transformer encoder로 구현되어 있다는 것은 잘 알고 계시리라 생각합니다. 이미 여러 번 다뤄보셨을 transformer의 모델 구조와 거의 유사하지만, 아래 그림과 같이 3개의 embedding 레이어를 가진다는 점에 유의해야 합니다.\n",
    "\n",
    "각 embedding의 자세한 구현 방법은 아래의 자료를 참고하세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8e36db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d44be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd5d7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c729efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b8d5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e275c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: position embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e31780a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e0116a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        \n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        \n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        \n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        \n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        \n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m) # (bs, n_head, Q_len, d_head)\n",
    "        \n",
    "        # transpose and liner\n",
    "        attn_out = tf.transpose(attn_out, perm=[0, 2, 1, 3]) # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out, [batch_size, -1, self.n_head * self.d_head])  # (batch_size, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "        \n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5dd91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10ca79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95533079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf08e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer class 정의\n",
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58922461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "813fe088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 8007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488235b",
   "metadata": {},
   "source": [
    "## 6. pretrain 진행\n",
    "---\n",
    "loss, accuracy 함수를 정의하고 Learning Rate 스케쥴링을 구현한 후, 10 Epoch까지 모델 학습을 시켜보세요. 학습을 진행할 때는 배치 사이즈에 유의하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e5560",
   "metadata": {},
   "source": [
    "## pretrain 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a18043a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 50  # mlm을 더 잘 학습하도록 50배 증가 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db3516b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # 정확도 계산\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6baa9b",
   "metadata": {},
   "source": [
    "Learning Rate 스케줄링도 아래와 같이 구현합니다. WarmUp 이후 consine 형태로 감소하는 스케줄을 적용합니다.\n",
    "\n",
    "최근에는 Learning Rate를 단순히 감소시키기 보다는 진동하면서 최적점을 찾아가는 방식을 많이 사용하고 있습니다. 다양한 방법을 찾아서 적용시켜 보는 것도 성능을 높이는 좋은 방법입니다.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c427096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8dc5a5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute lr \n",
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())\n",
    "\n",
    "# draw\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d15013a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 4485632     enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 8007)   0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 4,551,936\n",
      "Trainable params: 4,551,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f6bc3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 40000\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff09f1",
   "metadata": {},
   "source": [
    "## 7. 프로젝트 결과\n",
    "---\n",
    "학습된 모델과 학습과정을 시각화해 보세요. NSP와 MLM의 loss가 안정적으로 수렴하나요? 모델이 작기 때문에 loss가 잘 수렴하지 않을 수도 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95dd476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1600/1600 [==============================] - 226s 140ms/step - loss: 50.1677 - nsp_loss: 0.6660 - mlm_loss: 49.5017 - nsp_acc: 0.5674 - mlm_lm_acc: 0.1000 - val_loss: 45.5324 - val_nsp_loss: 0.6249 - val_mlm_loss: 44.9075 - val_nsp_acc: 0.6218 - val_mlm_lm_acc: 0.1155\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.09999, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 2/20\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 44.9730 - nsp_loss: 0.6458 - mlm_loss: 44.3272 - nsp_acc: 0.5936 - mlm_lm_acc: 0.1230 - val_loss: 43.0897 - val_nsp_loss: 0.6252 - val_mlm_loss: 42.4645 - val_nsp_acc: 0.6143 - val_mlm_lm_acc: 0.1262\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.09999 to 0.12305, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 3/20\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 42.7266 - nsp_loss: 0.6333 - mlm_loss: 42.0933 - nsp_acc: 0.6022 - mlm_lm_acc: 0.1312 - val_loss: 41.4526 - val_nsp_loss: 0.6176 - val_mlm_loss: 40.8350 - val_nsp_acc: 0.6302 - val_mlm_lm_acc: 0.1343\n",
      "\n",
      "Epoch 00003: mlm_lm_acc improved from 0.12305 to 0.13124, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 4/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 39.2996 - nsp_loss: 0.6292 - mlm_loss: 38.6703 - nsp_acc: 0.6073 - mlm_lm_acc: 0.1481 - val_loss: 36.3667 - val_nsp_loss: 0.6096 - val_mlm_loss: 35.7572 - val_nsp_acc: 0.6427 - val_mlm_lm_acc: 0.1673\n",
      "\n",
      "Epoch 00004: mlm_lm_acc improved from 0.13124 to 0.14810, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 5/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 35.0305 - nsp_loss: 0.6261 - mlm_loss: 34.4044 - nsp_acc: 0.6106 - mlm_lm_acc: 0.1833 - val_loss: 33.7350 - val_nsp_loss: 0.6009 - val_mlm_loss: 33.1341 - val_nsp_acc: 0.6391 - val_mlm_lm_acc: 0.2001\n",
      "\n",
      "Epoch 00005: mlm_lm_acc improved from 0.14810 to 0.18328, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 6/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 32.8282 - nsp_loss: 0.6205 - mlm_loss: 32.2077 - nsp_acc: 0.6157 - mlm_lm_acc: 0.2098 - val_loss: 32.3871 - val_nsp_loss: 0.5981 - val_mlm_loss: 31.7890 - val_nsp_acc: 0.6415 - val_mlm_lm_acc: 0.2191\n",
      "\n",
      "Epoch 00006: mlm_lm_acc improved from 0.18328 to 0.20981, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 7/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 31.5208 - nsp_loss: 0.6179 - mlm_loss: 30.9029 - nsp_acc: 0.6183 - mlm_lm_acc: 0.2269 - val_loss: 31.6443 - val_nsp_loss: 0.5952 - val_mlm_loss: 31.0491 - val_nsp_acc: 0.6471 - val_mlm_lm_acc: 0.2321\n",
      "\n",
      "Epoch 00007: mlm_lm_acc improved from 0.20981 to 0.22691, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 8/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 30.5690 - nsp_loss: 0.6161 - mlm_loss: 29.9529 - nsp_acc: 0.6199 - mlm_lm_acc: 0.2405 - val_loss: 31.1497 - val_nsp_loss: 0.5946 - val_mlm_loss: 30.5551 - val_nsp_acc: 0.6520 - val_mlm_lm_acc: 0.2419\n",
      "\n",
      "Epoch 00008: mlm_lm_acc improved from 0.22691 to 0.24054, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 9/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 29.8144 - nsp_loss: 0.6146 - mlm_loss: 29.1998 - nsp_acc: 0.6210 - mlm_lm_acc: 0.2516 - val_loss: 30.8376 - val_nsp_loss: 0.5932 - val_mlm_loss: 30.2444 - val_nsp_acc: 0.6513 - val_mlm_lm_acc: 0.2483\n",
      "\n",
      "Epoch 00009: mlm_lm_acc improved from 0.24054 to 0.25156, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 10/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 29.1819 - nsp_loss: 0.6129 - mlm_loss: 28.5690 - nsp_acc: 0.6256 - mlm_lm_acc: 0.2608 - val_loss: 30.5918 - val_nsp_loss: 0.5931 - val_mlm_loss: 29.9987 - val_nsp_acc: 0.6499 - val_mlm_lm_acc: 0.2525\n",
      "\n",
      "Epoch 00010: mlm_lm_acc improved from 0.25156 to 0.26079, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 11/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 28.6411 - nsp_loss: 0.6114 - mlm_loss: 28.0297 - nsp_acc: 0.6283 - mlm_lm_acc: 0.2686 - val_loss: 30.4740 - val_nsp_loss: 0.5998 - val_mlm_loss: 29.8742 - val_nsp_acc: 0.6381 - val_mlm_lm_acc: 0.2558\n",
      "\n",
      "Epoch 00011: mlm_lm_acc improved from 0.26079 to 0.26859, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 12/20\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 28.1641 - nsp_loss: 0.6099 - mlm_loss: 27.5542 - nsp_acc: 0.6296 - mlm_lm_acc: 0.2756 - val_loss: 30.3680 - val_nsp_loss: 0.5931 - val_mlm_loss: 29.7749 - val_nsp_acc: 0.6511 - val_mlm_lm_acc: 0.2581\n",
      "\n",
      "Epoch 00012: mlm_lm_acc improved from 0.26859 to 0.27559, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 13/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 27.7387 - nsp_loss: 0.6087 - mlm_loss: 27.1300 - nsp_acc: 0.6332 - mlm_lm_acc: 0.2820 - val_loss: 30.2673 - val_nsp_loss: 0.5913 - val_mlm_loss: 29.6760 - val_nsp_acc: 0.6483 - val_mlm_lm_acc: 0.2603\n",
      "\n",
      "Epoch 00013: mlm_lm_acc improved from 0.27559 to 0.28196, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 14/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 27.3591 - nsp_loss: 0.6079 - mlm_loss: 26.7512 - nsp_acc: 0.6358 - mlm_lm_acc: 0.2875 - val_loss: 30.2383 - val_nsp_loss: 0.5918 - val_mlm_loss: 29.6465 - val_nsp_acc: 0.6529 - val_mlm_lm_acc: 0.2614\n",
      "\n",
      "Epoch 00014: mlm_lm_acc improved from 0.28196 to 0.28749, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 15/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 27.0192 - nsp_loss: 0.6062 - mlm_loss: 26.4130 - nsp_acc: 0.6405 - mlm_lm_acc: 0.2926 - val_loss: 30.2349 - val_nsp_loss: 0.5924 - val_mlm_loss: 29.6425 - val_nsp_acc: 0.6504 - val_mlm_lm_acc: 0.2627\n",
      "\n",
      "Epoch 00015: mlm_lm_acc improved from 0.28749 to 0.29260, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 16/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 26.7114 - nsp_loss: 0.6053 - mlm_loss: 26.1061 - nsp_acc: 0.6437 - mlm_lm_acc: 0.2974 - val_loss: 30.2300 - val_nsp_loss: 0.5919 - val_mlm_loss: 29.6381 - val_nsp_acc: 0.6502 - val_mlm_lm_acc: 0.2636\n",
      "\n",
      "Epoch 00016: mlm_lm_acc improved from 0.29260 to 0.29744, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 17/20\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 26.4360 - nsp_loss: 0.6043 - mlm_loss: 25.8317 - nsp_acc: 0.6458 - mlm_lm_acc: 0.3016 - val_loss: 30.2256 - val_nsp_loss: 0.5934 - val_mlm_loss: 29.6322 - val_nsp_acc: 0.6507 - val_mlm_lm_acc: 0.2640\n",
      "\n",
      "Epoch 00017: mlm_lm_acc improved from 0.29744 to 0.30163, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 18/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 26.1909 - nsp_loss: 0.6033 - mlm_loss: 25.5876 - nsp_acc: 0.6470 - mlm_lm_acc: 0.3057 - val_loss: 30.2501 - val_nsp_loss: 0.5931 - val_mlm_loss: 29.6570 - val_nsp_acc: 0.6480 - val_mlm_lm_acc: 0.2645\n",
      "\n",
      "Epoch 00018: mlm_lm_acc improved from 0.30163 to 0.30571, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 19/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 25.9810 - nsp_loss: 0.6014 - mlm_loss: 25.3796 - nsp_acc: 0.6515 - mlm_lm_acc: 0.3089 - val_loss: 30.2470 - val_nsp_loss: 0.5924 - val_mlm_loss: 29.6546 - val_nsp_acc: 0.6502 - val_mlm_lm_acc: 0.2648\n",
      "\n",
      "Epoch 00019: mlm_lm_acc improved from 0.30571 to 0.30895, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n",
      "Epoch 20/20\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 25.8052 - nsp_loss: 0.6005 - mlm_loss: 25.2047 - nsp_acc: 0.6553 - mlm_lm_acc: 0.3115 - val_loss: 30.2831 - val_nsp_loss: 0.5931 - val_mlm_loss: 29.6901 - val_nsp_acc: 0.6527 - val_mlm_lm_acc: 0.2649\n",
      "\n",
      "Epoch 00020: mlm_lm_acc improved from 0.30895 to 0.31149, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train_8000.hdf5\n"
     ]
    }
   ],
   "source": [
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train_8000.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "# train\n",
    "history = pre_train_model.fit(pre_train_inputs, \n",
    "                              pre_train_labels, \n",
    "                              validation_split=0.2,\n",
    "                              epochs=epochs, \n",
    "                              batch_size=batch_size, \n",
    "                              callbacks=[save_weights])\n",
    "# 모델 인자에는 inputs, labels, epochs, batch size, callback 이 필요해요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31b6f564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training result\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
    "plt.plot(history.history['val_nsp_loss'], 'b--', label='val_nsp_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
    "plt.plot(history.history['val_nsp_acc'], 'g--', label='val_nsp_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history.history['mlm_loss'], 'r-', label='mlm_loss')\n",
    "plt.plot(history.history['val_mlm_loss'], 'r--', label='val_mlm_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(history.history['mlm_lm_acc'], 'k-', label='mlm_acc')\n",
    "plt.plot(history.history['val_mlm_lm_acc'], 'k--', label='val_mlm_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc028fa3",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "---\n",
    "\n",
    "- 배운 점\n",
    "    - additional_epoch 에 대해 알게 되었다 (`pretrained=True` )\n",
    "- 아쉬운 점\n",
    "    - 모델들에 대해 자세히 알아보고 싶은데 그럴 여유가 없다\n",
    "- 느낀 점\n",
    "    - 논문을 읽어보면 궁금한 점들이 해결이 된다는 것을 깨달았다\n",
    "- 어려웠던 점\n",
    "    - 모델들에 대해 자세하게 이해하는 것이 어렵다\n",
    "    - bert loss 관련해서 궁금해졌는데 내가 모르는 걸 설명하는 것도 상당히 어렵다는 것을 깨달았다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
